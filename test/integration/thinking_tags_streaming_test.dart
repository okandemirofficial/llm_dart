import 'dart:convert';
import 'dart:math';
import 'package:test/test.dart';
import 'package:llm_dart/llm_dart.dart';

/// Tests for thinking tags in streaming scenarios
///
/// This test suite specifically addresses the issue where \<think\>\</think\> tags
/// can be split across multiple chunks in streaming responses, making it
/// difficult to properly identify and extract thinking content.
void main() {
  group('Thinking Tags Streaming Tests', () {
    test('handles thinking tags split at tag boundaries', () {
      final decoder = Utf8StreamDecoder();

      // Test case that mimics the problem described in the issue
      final thinkingContent = '''<think>
è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„æ€è€ƒè¿‡ç¨‹
åŒ…å«å¤šè¡Œå†…å®¹å’Œä¸­æ–‡å­—ç¬¦
éœ€è¦ä»”ç»†åˆ†æç”¨æˆ·çš„é—®é¢˜
</think>

è¿™æ˜¯æ­£å¸¸çš„å›ç­”å†…å®¹ï¼Œç”¨æˆ·å¯ä»¥çœ‹åˆ°çš„éƒ¨åˆ†ã€‚''';

      final bytes = utf8.encode(thinkingContent);

      // Test splitting at various positions that would break tags
      final criticalPositions = [
        1, // Split after '<'
        6, // Split after '<think'
        7, // Split after '<think>'
        bytes.indexOf(utf8.encode('</think>')[0]), // Split at closing tag start
        bytes.indexOf(utf8.encode('</think>')[0]) +
            2, // Split in middle of closing tag
      ];

      for (final splitPos in criticalPositions) {
        if (splitPos >= bytes.length || splitPos <= 0) continue;

        decoder.reset();
        final result = StringBuffer();

        // Split into two parts at critical position
        final part1 = bytes.sublist(0, splitPos);
        final part2 = bytes.sublist(splitPos);

        result.write(decoder.decode(part1));
        result.write(decoder.decode(part2));
        result.write(decoder.flush());

        expect(result.toString(), equals(thinkingContent),
            reason: 'Failed when splitting at position: $splitPos');
      }
    });

    test('handles thinking tags with extreme fragmentation', () {
      final decoder = Utf8StreamDecoder();

      // Simulate the exact problem from the issue: tags split character by character
      final problematicContent = '''<think>
åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼š
1. ç”¨æˆ·æƒ³è¦äº†è§£æŸä¸ªæ¦‚å¿µ
2. éœ€è¦æä¾›æ¸…æ™°çš„è§£é‡Š
3. ä¸¾ä¾‹è¯´æ˜ä¼šæ›´å¥½
</think>

æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†è§£é‡Š...''';

      final bytes = utf8.encode(problematicContent);

      // Simulate very small chunks (1-3 bytes) that would split tags
      final result = StringBuffer();
      final random = Random(42); // Fixed seed for reproducible tests

      int i = 0;
      while (i < bytes.length) {
        final chunkSize = 1 + random.nextInt(3); // 1-3 bytes per chunk
        final end =
            (i + chunkSize < bytes.length) ? i + chunkSize : bytes.length;
        final chunk = bytes.sublist(i, end);

        result.write(decoder.decode(chunk));
        i = end;
      }
      result.write(decoder.flush());

      expect(result.toString(), equals(problematicContent));
    });

    test('handles multiple thinking blocks in one stream', () {
      final decoder = Utf8StreamDecoder();

      final multipleThinkingContent = '''<think>
ç¬¬ä¸€ä¸ªæ€è€ƒå—ï¼šåˆ†æé—®é¢˜
</think>

è¿™æ˜¯ç¬¬ä¸€éƒ¨åˆ†å›ç­”ã€‚

<think>
ç¬¬äºŒä¸ªæ€è€ƒå—ï¼šè€ƒè™‘è§£å†³æ–¹æ¡ˆ
åŒ…å«æ›´å¤šç»†èŠ‚
</think>

è¿™æ˜¯ç¬¬äºŒéƒ¨åˆ†å›ç­”ã€‚

<think>
ç¬¬ä¸‰ä¸ªæ€è€ƒå—ï¼šæ€»ç»“
</think>

æœ€ç»ˆçš„å›ç­”å†…å®¹ã€‚''';

      final bytes = utf8.encode(multipleThinkingContent);

      // Split at random positions to simulate real streaming
      final chunks = <List<int>>[];
      final random = Random(123); // Fixed seed
      int i = 0;
      while (i < bytes.length) {
        final chunkSize = 2 + random.nextInt(8); // 2-9 bytes per chunk
        final end =
            (i + chunkSize < bytes.length) ? i + chunkSize : bytes.length;
        chunks.add(bytes.sublist(i, end));
        i = end;
      }

      // Decode chunks
      final result = StringBuffer();
      for (final chunk in chunks) {
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      expect(result.toString(), equals(multipleThinkingContent));
    });

    test('handles thinking tags with mixed content types', () {
      final decoder = Utf8StreamDecoder();

      final mixedContent = '''<think>
æ€è€ƒå†…å®¹åŒ…å«ï¼š
- ä¸­æ–‡å­—ç¬¦ ğŸ¤”
- English text
- æ•°å­— 123
- ç‰¹æ®Šç¬¦å· @#\$%
- æ¢è¡Œç¬¦å’Œç©ºæ ¼
</think>

å›ç­”ï¼šè¿™æ˜¯ä¸€ä¸ªåŒ…å«å¤šç§å­—ç¬¦ç±»å‹çš„æµ‹è¯•ã€‚ğŸŒâœ¨''';

      final bytes = utf8.encode(mixedContent);

      // Test with single-byte chunks (worst case)
      final result = StringBuffer();
      for (final byte in bytes) {
        result.write(decoder.decode([byte]));
      }
      result.write(decoder.flush());

      expect(result.toString(), equals(mixedContent));
    });

    test('handles nested tags within thinking blocks', () {
      final decoder = Utf8StreamDecoder();

      final nestedContent = '''<think>
è¿™é‡Œæœ‰åµŒå¥—çš„æ ‡ç­¾ï¼š
<analysis>
  <step1>åˆ†æé—®é¢˜</step1>
  <step2>åˆ¶å®šæ–¹æ¡ˆ</step2>
</analysis>
<conclusion>å¾—å‡ºç»“è®º</conclusion>
</think>

åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘çš„å›ç­”æ˜¯...''';

      final bytes = utf8.encode(nestedContent);

      // Split at positions that might break nested tags
      final result = StringBuffer();
      for (int i = 0; i < bytes.length; i += 4) {
        final end = (i + 4 < bytes.length) ? i + 4 : bytes.length;
        final chunk = bytes.sublist(i, end);
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      expect(result.toString(), equals(nestedContent));
    });

    test('handles incomplete thinking tags at stream end', () {
      final decoder = Utf8StreamDecoder();

      // Test case where stream ends with incomplete thinking tag
      final incompleteContent = '''<think>
è¿™æ˜¯ä¸€ä¸ªæœªå®Œæˆçš„æ€è€ƒè¿‡ç¨‹
å¯èƒ½ç”±äºç½‘ç»œé—®é¢˜æˆ–å…¶ä»–åŸå› è¢«æˆªæ–­''';

      final bytes = utf8.encode(incompleteContent);

      // Process all bytes except the last few
      final result = StringBuffer();
      for (int i = 0; i < bytes.length; i += 3) {
        final end = (i + 3 < bytes.length) ? i + 3 : bytes.length;
        final chunk = bytes.sublist(i, end);
        result.write(decoder.decode(chunk));
      }

      // Flush should handle incomplete content gracefully
      final flushed = decoder.flush();
      result.write(flushed);

      expect(result.toString(), equals(incompleteContent));
    });

    test('handles thinking tags with various line endings', () {
      final decoder = Utf8StreamDecoder();

      final lineEndingVariants = [
        '<think>\næ€è€ƒå†…å®¹\n</think>\nå›ç­”å†…å®¹',
        '<think>\r\næ€è€ƒå†…å®¹\r\n</think>\r\nå›ç­”å†…å®¹',
        '<think>\ræ€è€ƒå†…å®¹\r</think>\rå›ç­”å†…å®¹',
        '<think>æ€è€ƒå†…å®¹</think>å›ç­”å†…å®¹', // No line endings
      ];

      for (final content in lineEndingVariants) {
        decoder.reset();
        final bytes = utf8.encode(content);

        // Split at random positions
        final result = StringBuffer();
        final random = Random(456); // Fixed seed
        int i = 0;
        while (i < bytes.length) {
          final chunkSize = 1 + random.nextInt(5);
          final end =
              (i + chunkSize < bytes.length) ? i + chunkSize : bytes.length;
          final chunk = bytes.sublist(i, end);
          result.write(decoder.decode(chunk));
          i = end;
        }
        result.write(decoder.flush());

        expect(result.toString(), equals(content),
            reason:
                'Failed for line ending variant: ${content.replaceAll('\n', '\\n').replaceAll('\r', '\\r')}');
      }
    });

    test('performance test with large thinking content', () {
      final decoder = Utf8StreamDecoder();

      // Generate large thinking content
      final largeThinking = StringBuffer();
      largeThinking.write('<think>\n');
      for (int i = 0; i < 1000; i++) {
        largeThinking.write('æ€è€ƒæ­¥éª¤ $i: è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„åˆ†æè¿‡ç¨‹ï¼ŒåŒ…å«ä¸­æ–‡å’Œæ•°å­—ã€‚\n');
      }
      largeThinking.write('</think>\n\n');
      largeThinking.write('åŸºäºä»¥ä¸Šè¯¦ç»†åˆ†æï¼Œæˆ‘çš„æœ€ç»ˆå›ç­”æ˜¯...');

      final content = largeThinking.toString();
      final bytes = utf8.encode(content);

      // Measure performance with small chunks
      final stopwatch = Stopwatch()..start();

      final result = StringBuffer();
      for (int i = 0; i < bytes.length; i += 5) {
        final end = (i + 5 < bytes.length) ? i + 5 : bytes.length;
        final chunk = bytes.sublist(i, end);
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      stopwatch.stop();

      expect(result.toString(), equals(content));
      expect(stopwatch.elapsedMilliseconds, lessThan(2000),
          reason: 'Large thinking content processing should be fast');
    });
  });
}
