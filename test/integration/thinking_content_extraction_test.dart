import 'dart:convert';
import 'dart:math';
import 'package:test/test.dart';
import 'package:llm_dart/llm_dart.dart';

/// Tests for thinking content extraction in streaming scenarios
///
/// This test suite simulates the real-world problem where thinking content
/// needs to be identified and extracted from streaming responses, even when
/// the \<think\>\</think\> tags are split across multiple chunks.
void main() {
  group('Thinking Content Extraction Tests', () {
    /// Helper function to extract thinking content from text
    String? extractThinkingContent(String text) {
      final thinkStart = text.indexOf('<think>');
      final thinkEnd = text.indexOf('</think>');

      if (thinkStart != -1 && thinkEnd != -1 && thinkEnd > thinkStart) {
        return text.substring(thinkStart + 7, thinkEnd);
      }
      return null;
    }

    /// Helper function to remove thinking content from text
    String removeThinkingContent(String text) {
      final regex = RegExp(r'<think>.*?</think>', dotAll: true);
      return text.replaceAll(regex, '').trim();
    }

    test('extracts thinking content correctly after streaming reconstruction',
        () {
      final decoder = Utf8StreamDecoder();

      // Simulate a response with thinking content
      final originalResponse = '''<think>
ç”¨æˆ·è¯¢é—®äº†ä¸€ä¸ªå…³äºç¼–ç¨‹çš„é—®é¢˜ã€‚
æˆ‘éœ€è¦ï¼š
1. åˆ†æé—®é¢˜çš„æ ¸å¿ƒ
2. æä¾›æ¸…æ™°çš„è§£é‡Š
3. ç»™å‡ºå®ç”¨çš„ç¤ºä¾‹
</think>

æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†è§£é‡Šç¼–ç¨‹æ¦‚å¿µ...''';

      final bytes = utf8.encode(originalResponse);

      // Simulate problematic chunking that splits the thinking tags
      final problematicChunks = [
        bytes.sublist(0, 2), // '<t'
        bytes.sublist(2, 5), // 'hin'
        bytes.sublist(5, 8), // 'k>\n'
        bytes.sublist(8, 20), // 'ç”¨æˆ·è¯¢é—®äº†ä¸€ä¸ªå…³äº'
        bytes.sublist(20, 40), // 'ç¼–ç¨‹çš„é—®é¢˜ã€‚\næˆ‘éœ€è¦ï¼š\n1.'
        bytes.sublist(40, 60), // ' åˆ†æé—®é¢˜çš„æ ¸å¿ƒ\n2. æä¾›'
        bytes.sublist(60, 80), // 'æ¸…æ™°çš„è§£é‡Š\n3. ç»™å‡ºå®ç”¨'
        bytes.sublist(80, 90), // 'çš„ç¤ºä¾‹\n</th'
        bytes.sublist(90, 95), // 'ink>'
        bytes.sublist(95), // '\n\næ ¹æ®æ‚¨çš„é—®é¢˜...'
      ];

      // Reconstruct the response using UTF8 decoder
      final result = StringBuffer();
      for (final chunk in problematicChunks) {
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      final reconstructedResponse = result.toString();

      // Verify the response was reconstructed correctly
      expect(reconstructedResponse, equals(originalResponse));

      // Extract thinking content
      final thinkingContent = extractThinkingContent(reconstructedResponse);
      expect(thinkingContent, isNotNull);
      expect(thinkingContent, contains('ç”¨æˆ·è¯¢é—®äº†ä¸€ä¸ªå…³äºç¼–ç¨‹çš„é—®é¢˜'));
      expect(thinkingContent, contains('åˆ†æé—®é¢˜çš„æ ¸å¿ƒ'));

      // Extract visible content (without thinking)
      final visibleContent = removeThinkingContent(reconstructedResponse);
      expect(visibleContent, equals('æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†è§£é‡Šç¼–ç¨‹æ¦‚å¿µ...'));
    });

    test('handles multiple thinking blocks in streaming', () {
      final decoder = Utf8StreamDecoder();

      final responseWithMultipleThinking = '''<think>
ç¬¬ä¸€ä¸ªæ€è€ƒï¼šåˆ†æç”¨æˆ·é—®é¢˜
</think>

è¿™æ˜¯ç¬¬ä¸€éƒ¨åˆ†å›ç­”ã€‚

<think>
ç¬¬äºŒä¸ªæ€è€ƒï¼šè€ƒè™‘æ›´æ·±å±‚çš„å«ä¹‰
éœ€è¦æä¾›æ›´å¤šç»†èŠ‚
</think>

è¿™æ˜¯ç¬¬äºŒéƒ¨åˆ†å›ç­”ã€‚

<think>
æœ€ç»ˆæ€è€ƒï¼šæ€»ç»“è¦ç‚¹
</think>

æœ€ç»ˆç»“è®ºã€‚''';

      final bytes = utf8.encode(responseWithMultipleThinking);

      // Create random chunks that might split thinking tags
      final chunks = <List<int>>[];
      final random = Random(789); // Fixed seed
      int i = 0;
      while (i < bytes.length) {
        final chunkSize = 3 + random.nextInt(10); // 3-12 bytes per chunk
        final end =
            (i + chunkSize < bytes.length) ? i + chunkSize : bytes.length;
        chunks.add(bytes.sublist(i, end));
        i = end;
      }

      // Reconstruct using decoder
      final result = StringBuffer();
      for (final chunk in chunks) {
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      final reconstructed = result.toString();
      expect(reconstructed, equals(responseWithMultipleThinking));

      // Verify we can extract all thinking blocks
      final allThinkingMatches = RegExp(r'<think>(.*?)</think>', dotAll: true)
          .allMatches(reconstructed);

      expect(allThinkingMatches.length, equals(3));

      final thinkingContents =
          allThinkingMatches.map((match) => match.group(1)?.trim()).toList();

      expect(thinkingContents[0], contains('ç¬¬ä¸€ä¸ªæ€è€ƒï¼šåˆ†æç”¨æˆ·é—®é¢˜'));
      expect(thinkingContents[1], contains('ç¬¬äºŒä¸ªæ€è€ƒï¼šè€ƒè™‘æ›´æ·±å±‚çš„å«ä¹‰'));
      expect(thinkingContents[2], contains('æœ€ç»ˆæ€è€ƒï¼šæ€»ç»“è¦ç‚¹'));
    });

    test('handles incomplete thinking tags gracefully', () {
      final decoder = Utf8StreamDecoder();

      // Simulate a case where the stream is cut off mid-thinking
      final incompleteResponse = '''<think>
è¿™æ˜¯ä¸€ä¸ªæœªå®Œæˆçš„æ€è€ƒè¿‡ç¨‹
å¯èƒ½ç”±äºç½‘ç»œä¸­æ–­è€Œè¢«æˆªæ–­
æ²¡æœ‰ç»“æŸæ ‡ç­¾''';

      final bytes = utf8.encode(incompleteResponse);

      // Process in small chunks
      final result = StringBuffer();
      for (int i = 0; i < bytes.length; i += 4) {
        final end = (i + 4 < bytes.length) ? i + 4 : bytes.length;
        final chunk = bytes.sublist(i, end);
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      final reconstructed = result.toString();
      expect(reconstructed, equals(incompleteResponse));

      // Should handle incomplete thinking tags gracefully
      final thinkingContent = extractThinkingContent(reconstructed);
      expect(thinkingContent, isNull); // No complete thinking block found
    });

    test('handles thinking tags with complex nested content', () {
      final decoder = Utf8StreamDecoder();

      final complexResponse = '''<think>
å¤æ‚çš„æ€è€ƒè¿‡ç¨‹åŒ…å«ï¼š
- åˆ—è¡¨é¡¹ç›®
- ä»£ç ç‰‡æ®µï¼š`function test() { return true; }`
- æ•°å­¦å…¬å¼ï¼šE = mcÂ²
- ç‰¹æ®Šå­—ç¬¦ï¼š@#\$%^&*()
- å¤šè¯­è¨€ï¼šHello, ä½ å¥½, ã“ã‚“ã«ã¡ã¯, ğŸŒ
- JSONæ•°æ®ï¼š{"key": "value", "number": 123}
</think>

åŸºäºå¤æ‚çš„åˆ†æï¼Œæˆ‘çš„å›ç­”æ˜¯...''';

      final bytes = utf8.encode(complexResponse);

      // Use very small chunks to maximize the chance of splitting
      final result = StringBuffer();
      for (final byte in bytes) {
        result.write(decoder.decode([byte]));
      }
      result.write(decoder.flush());

      final reconstructed = result.toString();
      expect(reconstructed, equals(complexResponse));

      // Verify thinking content extraction
      final thinkingContent = extractThinkingContent(reconstructed);
      expect(thinkingContent, isNotNull);
      expect(thinkingContent, contains('å¤æ‚çš„æ€è€ƒè¿‡ç¨‹åŒ…å«'));
      expect(thinkingContent, contains('function test()'));
      expect(thinkingContent, contains('E = mcÂ²'));
      expect(thinkingContent, contains('Hello, ä½ å¥½, ã“ã‚“ã«ã¡ã¯'));
    });

    test('simulates real-world streaming scenario', () async {
      // Simulate a real streaming scenario where chunks arrive at different times
      final decoder = Utf8StreamDecoder();

      final realWorldResponse = '''<think>
ç”¨æˆ·é—®äº†ä¸€ä¸ªå…³äºAIçš„é—®é¢˜ã€‚æˆ‘éœ€è¦ï¼š
1. ç†è§£é—®é¢˜çš„èƒŒæ™¯
2. æä¾›å‡†ç¡®çš„ä¿¡æ¯
3. ç¡®ä¿å›ç­”æœ‰ç”¨ä¸”æ˜“æ‡‚
</think>

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯ä¸€ä¸ªå¹¿æ³›çš„é¢†åŸŸï¼ŒåŒ…å«å¤šä¸ªå­é¢†åŸŸ...''';

      final bytes = utf8.encode(realWorldResponse);

      // Simulate realistic chunk sizes (like what you might get from an API)
      final realisticChunks = <List<int>>[];
      final chunkSizes = [1, 3, 2, 8, 5, 12, 7, 15, 4, 20, 10]; // Varying sizes

      int i = 0;
      for (final chunkSize in chunkSizes) {
        if (i >= bytes.length) break;
        final end =
            (i + chunkSize < bytes.length) ? i + chunkSize : bytes.length;
        realisticChunks.add(bytes.sublist(i, end));
        i = end;
      }

      // Add remaining bytes if any
      if (i < bytes.length) {
        realisticChunks.add(bytes.sublist(i));
      }

      // Process chunks as they would arrive in a real stream
      final result = StringBuffer();
      for (final chunk in realisticChunks) {
        final decoded = decoder.decode(chunk);
        result.write(decoded);

        // In a real application, you might try to extract thinking content
        // from partial results here, but it should handle incomplete tags gracefully
      }
      result.write(decoder.flush());

      final finalResult = result.toString();
      expect(finalResult, equals(realWorldResponse));

      // Final extraction should work correctly
      final thinkingContent = extractThinkingContent(finalResult);
      expect(thinkingContent, isNotNull);
      expect(thinkingContent, contains('ç”¨æˆ·é—®äº†ä¸€ä¸ªå…³äºAIçš„é—®é¢˜'));

      final visibleContent = removeThinkingContent(finalResult);
      expect(visibleContent, startsWith('äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯ä¸€ä¸ªå¹¿æ³›çš„é¢†åŸŸ'));
    });

    test('performance with large thinking content and small chunks', () {
      final decoder = Utf8StreamDecoder();

      // Generate a large response with substantial thinking content
      final largeThinking = StringBuffer();
      largeThinking.write('<think>\n');
      for (int i = 0; i < 500; i++) {
        largeThinking.write('æ€è€ƒæ­¥éª¤ $i: è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„åˆ†æè¿‡ç¨‹ï¼ŒåŒ…å«å¤æ‚çš„é€»è¾‘æ¨ç†ã€‚\n');
      }
      largeThinking.write('</think>\n\n');
      largeThinking.write('åŸºäºä»¥ä¸Šè¯¦ç»†åˆ†æï¼Œæˆ‘çš„å›ç­”æ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªå¤æ‚é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚');

      final largeResponse = largeThinking.toString();
      final bytes = utf8.encode(largeResponse);

      // Measure performance with very small chunks
      final stopwatch = Stopwatch()..start();

      final result = StringBuffer();
      // Use 2-byte chunks to maximize processing overhead
      for (int i = 0; i < bytes.length; i += 2) {
        final end = (i + 2 < bytes.length) ? i + 2 : bytes.length;
        final chunk = bytes.sublist(i, end);
        result.write(decoder.decode(chunk));
      }
      result.write(decoder.flush());

      stopwatch.stop();

      // Verify correctness
      expect(result.toString(), equals(largeResponse));

      // Verify performance (should be reasonable even with small chunks)
      expect(stopwatch.elapsedMilliseconds, lessThan(3000),
          reason:
              'Large content processing with small chunks should be efficient');

      // Verify thinking content extraction still works
      final thinkingContent = extractThinkingContent(result.toString());
      expect(thinkingContent, isNotNull);
      expect(thinkingContent, contains('æ€è€ƒæ­¥éª¤ 0'));
      expect(thinkingContent, contains('æ€è€ƒæ­¥éª¤ 499'));
    });
  });
}
