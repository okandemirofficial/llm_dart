import 'dart:io';
import 'package:llm_dart/llm_dart.dart';

/// Content moderation examples using ModerationCapability interface
///
/// This example demonstrates:
/// - Basic content moderation
/// - Batch processing
/// - Category analysis
Future<void> main() async {
  print('ğŸ›¡ï¸ Content Moderation Examples\n');

  final apiKey = Platform.environment['OPENAI_API_KEY'];
  if (apiKey == null) {
    print('âŒ Please set OPENAI_API_KEY environment variable');
    return;
  }

  try {
    final provider = await ai().openai().apiKey(apiKey).buildModeration();

    await demonstrateBasicModeration(provider, 'OpenAI');
    await demonstrateBatchModeration(provider, 'OpenAI');
  } catch (e) {
    print('âŒ Failed to initialize moderation: $e');
  }

  print('âœ… Content moderation examples completed!');
}

/// Demonstrate basic content moderation
Future<void> demonstrateBasicModeration(
    ModerationCapability provider, String providerName) async {
  print('ğŸ” Basic Content Moderation ($providerName):\n');

  final testContents = [
    'Hello, how are you today?', // Safe content
    'This is a normal conversation.', // Safe content
    'Thank you for your help!', // Safe content
  ];

  for (int i = 0; i < testContents.length; i++) {
    final content = testContents[i];
    print('   ğŸ“ Testing: "$content"');

    try {
      final request = ModerationRequest(input: content);
      final result = await provider.moderate(request);

      final firstResult = result.results.first;
      final status = firstResult.flagged ? 'ğŸš¨ FLAGGED' : 'âœ… SAFE';
      print('         $status (ID: ${result.id})');

      if (firstResult.flagged) {
        print('         âš ï¸  Content flagged for review');
      }
    } catch (e) {
      print('         âŒ Moderation failed: $e');
    }
    print('');
  }
}

/// Demonstrate batch moderation processing
Future<void> demonstrateBatchModeration(
    ModerationCapability provider, String providerName) async {
  print('ğŸ“¦ Batch Moderation ($providerName):\n');

  final batchContent = [
    'Welcome to our platform!',
    'Please follow our community guidelines.',
    'Thank you for your contribution.',
    'This is educational content about safety.',
    'Let\'s have a respectful discussion.',
  ];

  print('   ğŸ”„ Processing ${batchContent.length} items in batch...');
  final startTime = DateTime.now();

  final results = <ModerationResponse>[];
  for (final content in batchContent) {
    try {
      final request = ModerationRequest(input: content);
      final result = await provider.moderate(request);
      results.add(result);
    } catch (e) {
      print('   âŒ Failed to moderate: "$content" - $e');
    }
  }

  final duration = DateTime.now().difference(startTime);
  print('   âœ… Batch completed in ${duration.inMilliseconds}ms');

  // Analyze batch results
  final flaggedCount = results.where((r) => r.results.first.flagged).length;
  final safeCount = results.length - flaggedCount;

  print('   ğŸ“Š Batch Results:');
  print('      âœ… Safe: $safeCount');
  print('      ğŸš¨ Flagged: $flaggedCount');
  print(
      '      ğŸ“ˆ Safety rate: ${(safeCount / results.length * 100).toStringAsFixed(1)}%');
}
